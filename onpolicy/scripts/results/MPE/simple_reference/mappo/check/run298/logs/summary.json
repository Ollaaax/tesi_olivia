{"/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent0/value_loss/agent0/value_loss": [[1731269335.538522, 3200, 0.07736477802197138]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent0/policy_loss/agent0/policy_loss": [[1731269335.542059, 3200, -1.1523565083641311e-09]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent0/dist_entropy/agent0/dist_entropy": [[1731269335.544512, 3200, 1.0140407800674438]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent0/actor_grad_norm/agent0/actor_grad_norm": [[1731269335.5462458, 3200, 0.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent0/critic_grad_norm/agent0/critic_grad_norm": [[1731269335.5483499, 3200, 0.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent0/ratio/agent0/ratio": [[1731269335.5502021, 3200, 1.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent0/individual_rewards/agent0/individual_rewards": [[1731269335.5521028, 3200, -0.28863474359459695]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent0/average_episode_rewards/agent0/average_episode_rewards": [[1731269335.553691, 3200, -21.476945281028748]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent1/value_loss/agent1/value_loss": [[1731269335.5553532, 3200, 0.07534793665011724]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent1/policy_loss/agent1/policy_loss": [[1731269335.557077, 3200, 3.218650803660239e-08]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent1/dist_entropy/agent1/dist_entropy": [[1731269335.5587451, 3200, 0.9655454913775127]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent1/actor_grad_norm/agent1/actor_grad_norm": [[1731269335.560831, 3200, 0.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent1/critic_grad_norm/agent1/critic_grad_norm": [[1731269335.5628428, 3200, 0.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent1/ratio/agent1/ratio": [[1731269335.564928, 3200, 1.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent1/individual_rewards/agent1/individual_rewards": [[1731269335.566611, 3200, -0.28774330438897155]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run298/logs/agent1/average_episode_rewards/agent1/average_episode_rewards": [[1731269335.568244, 3200, -21.476945281028748]]}