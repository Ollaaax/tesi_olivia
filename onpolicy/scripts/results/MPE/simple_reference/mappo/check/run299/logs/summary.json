{"/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent0/value_loss/agent0/value_loss": [[1731269384.121547, 3200, 0.07736477802197138]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent0/policy_loss/agent0/policy_loss": [[1731269384.123311, 3200, -1.1523565083641311e-09]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent0/dist_entropy/agent0/dist_entropy": [[1731269384.125192, 3200, 1.0140407800674438]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent0/actor_grad_norm/agent0/actor_grad_norm": [[1731269384.126805, 3200, 0.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent0/critic_grad_norm/agent0/critic_grad_norm": [[1731269384.12864, 3200, 0.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent0/ratio/agent0/ratio": [[1731269384.130361, 3200, 1.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent0/individual_rewards/agent0/individual_rewards": [[1731269384.132071, 3200, -0.28863474359459695]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent0/average_episode_rewards/agent0/average_episode_rewards": [[1731269384.133754, 3200, -21.476945281028748]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent1/value_loss/agent1/value_loss": [[1731269384.1353621, 3200, 0.07534793665011724]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent1/policy_loss/agent1/policy_loss": [[1731269384.137066, 3200, 3.218650803660239e-08]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent1/dist_entropy/agent1/dist_entropy": [[1731269384.138711, 3200, 0.9655454913775127]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent1/actor_grad_norm/agent1/actor_grad_norm": [[1731269384.1403258, 3200, 0.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent1/critic_grad_norm/agent1/critic_grad_norm": [[1731269384.14209, 3200, 0.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent1/ratio/agent1/ratio": [[1731269384.143633, 3200, 1.0]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent1/individual_rewards/agent1/individual_rewards": [[1731269384.145251, 3200, -0.28774330438897155]], "/Users/ollae/Desktop/Tesi/on-policy/onpolicy/scripts/results/MPE/simple_reference/mappo/check/run299/logs/agent1/average_episode_rewards/agent1/average_episode_rewards": [[1731269384.1467588, 3200, -21.476945281028748]]}